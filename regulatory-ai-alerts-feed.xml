<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>State AI Regulatory Intelligence - Colorado &amp; California</title>
    <link>https://regulatory-intel-demo.github.io</link>
    <description>Regulatory change alerts for artificial intelligence legislation and rulemaking activity across monitored U.S. states. This feed tracks proposed rules, enacted legislation, enforcement guidance, and agency actions relevant to AI governance and algorithmic accountability.</description>
    <language>en-us</language>
    <lastBuildDate>Wed, 25 Feb 2026 08:00:00 -0700</lastBuildDate>
    <atom:link href="https://kbandrews.github.io/regulatory-intel-feed/regulatory-ai-alerts-feed.xml" rel="self" type="application/rss+xml"/>
    <category>Artificial Intelligence Regulation</category>
    <category>State Regulatory Change</category>

    <item>
      <title>CO - Attorney General Proposes Draft Rules for Colorado AI Act (SB 24-205) Implementation</title>
      <link>https://coag.gov/ai/</link>
      <description>The Colorado Attorney General's Office has published proposed rules for implementation of the Colorado Artificial Intelligence Act (SB 24-205), now set to take effect June 30, 2026. The proposed rules address key compliance requirements for deployers of high-risk AI systems, including: (1) standards for risk management policies and programs; (2) required elements of impact assessments for high-risk systems making consequential decisions; (3) specifications for consumer notification and appeal processes; and (4) criteria for recognized AI risk management frameworks that establish the affirmative defense. Of particular note for healthcare deployers, the rules clarify that AI systems used in claims adjudication, prior authorization, and utilization management that make or substantially influence coverage determinations constitute high-risk systems subject to full compliance obligations. The public comment period is open through March 20, 2026. A rulemaking hearing is scheduled for April 8, 2026.</description>
      <category>Colorado</category>
      <category>Rulemaking</category>
      <category>SB 24-205</category>
      <category>Healthcare AI</category>
      <pubDate>Mon, 23 Feb 2026 09:00:00 -0700</pubDate>
      <guid isPermaLink="false">CO-AG-RULES-2026-001</guid>
    </item>

    <item>
      <title>CA - California Civil Rights Department Issues Updated Guidance on AI in Healthcare Coverage Decisions</title>
      <link>https://calcivilrights.ca.gov/2025/06/30/civil-rights-council-secures-approval-for-regulations-to-protect-against-employment-discrimination-related-to-artificial-intelligence/</link>
      <description>The California Civil Rights Department (CRD) has released an interpretive guidance bulletin addressing the use of artificial intelligence and automated decision-making systems in healthcare coverage and benefits determinations. Building on the employment-focused AI regulations finalized in June 2025, this guidance extends algorithmic discrimination principles to health plan administration. The bulletin states that health insurers and plan administrators using AI tools for prior authorization, claims processing, or medical necessity determinations must ensure such systems do not produce discriminatory outcomes based on race, disability, age, sex, or other protected characteristics under the Unruh Civil Rights Act and California Insurance Code. Insurers are advised to conduct disparate impact analyses on AI-driven denial rates and maintain documentation of algorithmic fairness testing. CRD indicates it will coordinate enforcement with the California Department of Insurance and the Department of Managed Health Care. Compliance is expected to align with existing fair claims settlement practices requirements.</description>
      <category>California</category>
      <category>Guidance</category>
      <category>Healthcare AI</category>
      <category>Algorithmic Discrimination</category>
      <pubDate>Thu, 19 Feb 2026 10:30:00 -0800</pubDate>
      <guid isPermaLink="false">CA-CRD-GUIDANCE-2026-003</guid>
    </item>

    <item>
      <title>CO - HB 26-1087 Introduced: Amendments to Colorado AI Act Narrowing High-Risk System Definition</title>
      <link>https://leg.colorado.gov/bills/sb24-205</link>
      <description>Colorado House Bill 26-1087 has been introduced in the 2026 regular legislative session proposing amendments to the Colorado Artificial Intelligence Act (SB 24-205) prior to its June 30, 2026 effective date. Key proposed changes include: (1) narrowing the definition of "high-risk artificial intelligence system" to exclude AI systems that provide recommendations subject to meaningful human review before a consequential decision is finalized; (2) expanding the small business exemption threshold from 50 to 100 full-time employees; (3) reducing deployer impact assessment frequency from annual to biennial for systems that have not been substantially modified; and (4) creating a new safe harbor for deployers who can demonstrate compliance with NIST AI Risk Management Framework (AI RMF 1.0) or ISO/IEC 42001. The bill has been referred to the House Business Affairs and Labor Committee. Healthcare industry groups have submitted testimony arguing that the human review exemption should apply to AI-assisted clinical decision support tools used in utilization management.</description>
      <category>Colorado</category>
      <category>Legislation</category>
      <category>SB 24-205 Amendment</category>
      <category>High-Risk AI Definition</category>
      <pubDate>Tue, 17 Feb 2026 14:00:00 -0700</pubDate>
      <guid isPermaLink="false">CO-HB26-1087-INTRO</guid>
    </item>

    <item>
      <title>CA - SB 53 Compliance Deadline: Frontier AI Developers Must Publish Safety Protocols by March 1, 2026</title>
      <link>https://leginfo.legislature.ca.gov/faces/billNavClient.xhtml?bill_id=202520260SB53</link>
      <description>The California Department of Technology has issued a compliance reminder that large frontier AI developers subject to the Transparency in Frontier Artificial Intelligence Act (SB 53) must publish their safety and security protocols on their public websites no later than March 1, 2026. SB 53, signed by Governor Newsom on September 29, 2025 and effective January 1, 2026, requires developers of frontier models trained using computational resources exceeding 10^26 integer or floating-point operations, with annual revenue exceeding $500 million, to maintain comprehensive safety frameworks. Organizations that license, deploy, or integrate frontier models from covered developers should review published safety protocols to assess downstream compliance obligations and ensure alignment with internal AI governance frameworks. Healthcare organizations deploying frontier model capabilities in member-facing applications such as chatbots, symptom checkers, or virtual health assistants should evaluate whether their AI vendors qualify as covered developers and review vendor safety protocol disclosures.</description>
      <category>California</category>
      <category>Compliance Deadline</category>
      <category>SB 53</category>
      <category>Frontier AI</category>
      <pubDate>Fri, 13 Feb 2026 11:00:00 -0800</pubDate>
      <guid isPermaLink="false">CA-SB53-DEADLINE-2026-001</guid>
    </item>

    <item>
      <title>CO - Colorado Division of Insurance Bulletin: AI Governance Expectations for Health Insurance Carriers</title>
      <link>https://doi.colorado.gov/for-consumers/sb21-169-protecting-consumers-from-unfair-discrimination-in-insurance-practices</link>
      <description>The Colorado Division of Insurance (DOI) has issued Bulletin No. B-2026-03 establishing supervisory expectations for health insurance carriers regarding the governance of artificial intelligence systems used in insurance operations. The bulletin references both the Colorado AI Act (SB 24-205) and existing unfair claims settlement practices statutes. Key expectations include: (1) carriers must maintain an enterprise AI inventory documenting all AI systems used in underwriting, claims processing, utilization management, provider network management, and member communications; (2) carriers must designate a senior officer responsible for AI governance and compliance; (3) AI systems that influence coverage determinations, benefit calculations, or claims adjudication must be subject to periodic bias testing with results documented and available for examination; (4) carriers must establish protocols for human review of AI-influenced adverse determinations. The DOI indicates these expectations will be incorporated into the market conduct examination process beginning Q3 2026. Carriers are encouraged to begin self-assessment immediately.</description>
      <category>Colorado</category>
      <category>Insurance Bulletin</category>
      <category>AI Governance</category>
      <category>Health Insurance</category>
      <pubDate>Mon, 09 Feb 2026 08:30:00 -0700</pubDate>
      <guid isPermaLink="false">CO-DOI-BULLETIN-2026-03</guid>
    </item>

    <item>
      <title>CA - AB 853 Implementation: AI Transparency Act Disclosure Requirements Effective August 2026</title>
      <link>https://leginfo.legislature.ca.gov/faces/billNavClient.xhtml?bill_id=202520260AB853</link>
      <description>The California Department of Technology has published implementation guidance for Assembly Bill 853, which expands upon and delays the effective date of the California AI Transparency Act (SB 942). Under AB 853, AI system developers with over one million monthly users operating in California must provide free detection tools allowing users to determine whether content was generated or substantially modified by AI. The expanded requirements under AB 853 add obligations for large online platforms to disclose system provenance information indicating whether content was AI-generated. Healthcare organizations that deploy patient-facing generative AI applications, including virtual health assistants, AI-generated health education materials, automated member correspondence, and AI-drafted explanation of benefits communications, should evaluate whether their AI tools or vendor platforms meet the coverage thresholds. Organizations are advised to begin planning for disclosure mechanisms and content labeling infrastructure. The compliance deadline is August 1, 2026.</description>
      <category>California</category>
      <category>Implementation Guidance</category>
      <category>AB 853</category>
      <category>AI Transparency</category>
      <pubDate>Wed, 04 Feb 2026 09:15:00 -0800</pubDate>
      <guid isPermaLink="false">CA-AB853-IMPL-2026-001</guid>
    </item>

    <item>
      <title>CO - SB 26-042 Introduced: AI Impact Assessment Requirements for State-Regulated Health Plans</title>
      <link>https://leg.colorado.gov/bills</link>
      <description>Colorado Senate Bill 26-042 has been introduced to establish specific AI impact assessment requirements for health insurance carriers and managed care organizations regulated by the Colorado Division of Insurance. Building on the framework established by SB 24-205, this bill would require state-regulated health plans to: (1) conduct and submit annual AI impact assessments to the Division of Insurance for each AI system used in claims adjudication, prior authorization, or utilization review; (2) include in each assessment a quantitative analysis of denial rates by demographic group and geographic region to identify potential algorithmic discrimination; (3) provide the Division of Insurance with access to algorithmic audit results upon request during market conduct examinations; and (4) notify covered members when an AI system has been a substantial factor in an adverse benefit determination, along with instructions for requesting human review. The bill has been referred to the Senate Health and Human Services Committee. A fiscal note is pending. Healthcare industry stakeholders have requested a hearing to discuss implementation timelines and technical feasibility of demographic analysis requirements.</description>
      <category>Colorado</category>
      <category>Legislation</category>
      <category>Health Insurance AI</category>
      <category>Impact Assessment</category>
      <pubDate>Fri, 30 Jan 2026 15:45:00 -0700</pubDate>
      <guid isPermaLink="false">CO-SB26-042-INTRO</guid>
    </item>

    <item>
      <title>CA - California Department of Insurance Opens Investigation into AI-Driven Claims Denials</title>
      <link>https://www.insurance.ca.gov/</link>
      <description>California Insurance Commissioner Ricardo Lara has announced the opening of a market conduct investigation into the use of artificial intelligence systems for health insurance claims adjudication by multiple large health insurers operating in California. The investigation follows consumer complaints and media reports alleging that AI-powered claims processing systems are generating coverage denials without adequate individualized review of patient medical records. The Department of Insurance stated it will examine whether AI-driven claims adjudication practices comply with California's fair claims settlement practices regulations (Cal. Code Regs., tit. 10, section 2695.7), the Timely Claims Settlement Act, and anti-discrimination requirements under the Unruh Civil Rights Act. The Commissioner's office has issued data requests to affected carriers seeking documentation of AI system validation, human oversight protocols, denial rate analytics, and algorithmic bias testing results. Insurers operating AI claims systems in California should review their compliance documentation and prepare for potential regulatory inquiries. The investigation scope includes AI systems used for prior authorization, concurrent review, retrospective review, and payment integrity.</description>
      <category>California</category>
      <category>Enforcement</category>
      <category>AI Claims Processing</category>
      <category>Investigation</category>
      <pubDate>Mon, 26 Jan 2026 13:00:00 -0800</pubDate>
      <guid isPermaLink="false">CA-CDI-INVESTIGATION-2026-001</guid>
    </item>

    <item>
      <title>CO - Colorado AG Designates NIST AI RMF 1.0 as Recognized Framework Under SB 24-205</title>
      <link>https://coag.gov/app/uploads/2024/09/09.10.2024-AI-Pre-Rulemaking-Considerations-for-the-ADAI-1.pdf</link>
      <description>The Colorado Attorney General has formally designated the National Institute of Standards and Technology Artificial Intelligence Risk Management Framework (NIST AI RMF 1.0) as a nationally recognized risk management framework under Section 6-1-1702(6) of the Colorado Artificial Intelligence Act (SB 24-205). Organizations that demonstrate compliance with NIST AI RMF 1.0 may assert an affirmative defense in enforcement actions brought under the Act. The designation notice specifies that to qualify for the affirmative defense, deployers must demonstrate comprehensive implementation across all four functions of the framework (Govern, Map, Measure, Manage) as applied to each high-risk AI system. Partial or selective implementation of individual framework components will not satisfy the affirmative defense standard. The Attorney General's office indicated that additional frameworks, including ISO/IEC 42001 and the IEEE 7000 series, are under review for potential future designation. Healthcare deployers are encouraged to evaluate their current AI governance programs against the NIST AI RMF and document alignment across all framework functions for each deployed high-risk system.</description>
      <category>Colorado</category>
      <category>Framework Designation</category>
      <category>NIST AI RMF</category>
      <category>SB 24-205</category>
      <pubDate>Wed, 21 Jan 2026 10:00:00 -0700</pubDate>
      <guid isPermaLink="false">CO-AG-FRAMEWORK-2026-001</guid>
    </item>

  </channel>
</rss>
